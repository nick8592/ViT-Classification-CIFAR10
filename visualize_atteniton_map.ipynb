{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import datetime\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from model import VisionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameters():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Test Arguments\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=2)\n",
    "    parser.add_argument(\"--device\", type=str, default=\"mps\", choices=[\"cpu\", \"cuda\", \"mps\"])\n",
    "    parser.add_argument(\"--output_path\", type=str, default='./output')\n",
    "    parser.add_argument(\"--timestamp\", type=str, default=\"1900-01-01-00-00\")\n",
    "    parser.add_argument(\"--mode\", type=str, default=\"cifar\", choices=['cifar', 'single-cifar', 'custom'])\n",
    "    parser.add_argument(\"--no_image\", default=False, action='store_true')\n",
    "\n",
    "    # Data Arguments\n",
    "    parser.add_argument(\"--image_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--n_channels\", type=int, default=3)\n",
    "    parser.add_argument(\"--patch_size\", type=int, default=4)\n",
    "    parser.add_argument(\"--n_classes\", type=int, default=10)\n",
    "    parser.add_argument(\"--data_path\", type=str, default='./data')\n",
    "    parser.add_argument(\"--num_test_images\", type=int, default=None)\n",
    "    parser.add_argument(\"--index\", type=int, default=1)\n",
    "    parser.add_argument(\"--image_path\", type=str, default=None)\n",
    "\n",
    "    # ViT Arguments\n",
    "    parser.add_argument(\"--embed_dim\", type=int, default=128)\n",
    "    parser.add_argument(\"--n_layers\", type=int, default=6)\n",
    "    parser.add_argument(\"--n_attention_heads\", type=int, default=4)\n",
    "    parser.add_argument(\"--forward_mul\", type=int, default=2)\n",
    "    parser.add_argument(\"--dropout\", type=int, default=0.1)\n",
    "    parser.add_argument(\"--model_path\", type=str, default='model/vit-classification-cifar10-colab-t4/ViT_model_199.pt')\n",
    "\n",
    "    args = parser.parse_args(\"\") # https://stackoverflow.com/a/69925856\n",
    "    return args\n",
    "\n",
    "args = hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set CIFAR-10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Image shape: torch.Size([3, 32, 32])\n",
      "Label: 8\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize([args.image_size, args.image_size]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "testset = torchvision.datasets.CIFAR10(root=args.data_path, train=False, \n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "image, label = testset.__getitem__(args.index)\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = (image / 2 + 0.5).numpy()\n",
    "plt.imshow(np.transpose(img, (1, 2, 0))) # (c, h, w) -> (h, w, c)\n",
    "plt.title(classes[label])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Vision Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (embedding): EmbedLayer(\n",
      "    (conv1): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): ModuleList(\n",
      "    (0-5): 6 x Encoder(\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attention): SelfAttention(\n",
      "        (queries): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (keys): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (values): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (out_projection): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (activation): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (classifier): Classifier(\n",
      "    (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (activation): Tanh()\n",
      "    (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = VisionTransformer(args.n_channels, args.embed_dim, args.n_layers, \n",
    "                              args.n_attention_heads, args.forward_mul, args.image_size, \n",
    "                              args.patch_size, args.n_classes, args.dropout)\n",
    "model.load_state_dict(torch.load(args.model_path, weights_only=True, map_location=args.device))\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass image through ViT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = model(image.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create folder for attention map output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = datetime.datetime.now()\n",
    "# timestamp = str(time.strftime('%Y-%m-%d-%H-%M'))\n",
    "# os.makedirs(f\"attention_data/{timestamp}\", exist_ok=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
